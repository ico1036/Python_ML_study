{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7000, 3)\n",
      "(3000, 3)\n",
      "(7000, 1)\n",
      "(3000, 1)\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "xy=np.loadtxt('data.csv', delimiter=',', dtype=np.float)\n",
    "np.random.shuffle(xy)\n",
    "x_data = xy[:,1:-1]\n",
    "y_data = xy[:,[-1]]\n",
    "\n",
    "# training data & test data\n",
    "tr = int(x_data.shape[0]*0.7)\n",
    "x_train = x_data[0:tr,:]\n",
    "y_train = y_data[0:tr,:]\n",
    "x_test = x_data[tr:,:]\n",
    "y_test = y_data[tr:,:]\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "# HyperParameter\n",
    "batch_size = 32\n",
    "training_epochs=10\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Place holder\n",
    "X = tf.placeholder(tf.float32,[None,3])\n",
    "Y = tf.placeholder(tf.float32,[None,1])\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Input Layer\n",
    "W1 = tf.get_variable(\"W1\", shape=[3, 50],initializer=tf.contrib.layers.xavier_initializer()) \n",
    "b1  = tf.Variable(tf.random_normal([50]),name='bias1')\n",
    "L1  =tf.nn.relu(tf.matmul(X,W1)+b1)\n",
    "L1 =tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "# Output Layer\n",
    "W2 = tf.get_variable(\"W2\", shape=[50, 3],initializer=tf.contrib.layers.xavier_initializer()) \n",
    "b2  = tf.Variable(tf.random_normal([3]),name='bias2')\n",
    "hypothesis  =tf.nn.sigmoid(tf.matmul(L1,W2)+b2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# loss, optimizer\n",
    "loss = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y) * tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Acc & Prediction\n",
    "predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started\n",
      "('Epoch:', '0001', 'Loss =, 0.836646250   Acc: 80.21%')\n",
      "('Epoch:', '0002', 'Loss =, 0.356351726   Acc: 90.62%')\n",
      "('Epoch:', '0003', 'Loss =, 0.243936399   Acc: 97.92%')\n",
      "('Epoch:', '0004', 'Loss =, 0.189683982   Acc: 91.67%')\n",
      "('Epoch:', '0005', 'Loss =, 0.161084523   Acc: 98.96%')\n",
      "('Epoch:', '0006', 'Loss =, 0.140679685   Acc: 98.96%')\n",
      "('Epoch:', '0007', 'Loss =, 0.123694528   Acc: 96.88%')\n",
      "('Epoch:', '0008', 'Loss =, 0.113325062   Acc: 98.96%')\n",
      "('Epoch:', '0009', 'Loss =, 0.102871756   Acc: 97.92%')\n",
      "('Epoch:', '0010', 'Loss =, 0.094707756   Acc: 100.00%')\n",
      "Learning Finished\n"
     ]
    }
   ],
   "source": [
    "# Initialize \n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "\n",
    "# Train\n",
    "print('Learning started')\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    batch_count = int(x_train.shape[0]/batch_size)\n",
    "    avg_loss = 0\n",
    "    for i in range(batch_count):\n",
    "        batch_xs, batch_ys = x_train[i*batch_size : i*batch_size+batch_size],y_train[i*batch_size : i*batch_size+batch_size]\n",
    "        feed_dict = feed_dict={X: batch_xs, Y: batch_ys , keep_prob: 0.7}\n",
    "        c,acc,_ = sess.run([loss,accuracy,train],feed_dict=feed_dict) \n",
    "        avg_loss += c / batch_count\n",
    "    print('Epoch:', '%04d' % (epoch+1), \"Loss =, {:.9f}   Acc: {:.2%}\".format(avg_loss,acc))\n",
    "print('Learning Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Accuracy', 0.9917778)\n"
     ]
    }
   ],
   "source": [
    "#Test model and check accuracy\n",
    "print('Accuracy', sess.run(accuracy, feed_dict={X: x_test, Y: y_test, keep_prob:1}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow_",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
